{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5Fy2JT9JJBqBdwjvyOb5H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElwinGao4444/colab/blob/main/%E6%89%8B%E6%92%B8%E7%BB%8F%E5%85%B8%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 手撸经典神经网络"
      ],
      "metadata": {
        "id": "2yRrcOr_xguE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "m3AyFRnuxin8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu = tf.config.list_physical_devices('GPU')\n",
        "print('gpu: ', gpu)\n",
        "cpu = tf.config.list_physical_devices('CPU')\n",
        "print('cpu: ', cpu)"
      ],
      "metadata": {
        "id": "CUsgubjOxksT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LeNet"
      ],
      "metadata": {
        "id": "DH5cVc9Hxnfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = tf.expand_dims(x_train, axis=3) / 255\n",
        "x_test = tf.expand_dims(x_test, axis=3) / 255\n",
        "x_train.shape"
      ],
      "metadata": {
        "id": "gFg6g_lTxn4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(28,28,1), dtype=\"float\"),\n",
        "    tf.keras.layers.Conv2D(6, 5, activation='sigmoid', padding='same'),     # 5x5卷积，6通道\n",
        "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2),                      # 2x2窗口，步幅2\n",
        "    tf.keras.layers.Conv2D(16, 5, activation='sigmoid'),                    # 5x5卷积，16通道\n",
        "    tf.keras.layers.AvgPool2D(pool_size=2, strides=2),                      # 2x2窗口，步幅2\n",
        "    tf.keras.layers.Flatten(),  # 二维压缩成一维\n",
        "    tf.keras.layers.Dense(120, activation='sigmoid'),   # 120特征全连接层\n",
        "    tf.keras.layers.Dense(84, activation='sigmoid'),   # 84特征全连接层\n",
        "    tf.keras.layers.Dense(10),              # 10特征全连接层\n",
        "])\n",
        "model.summary()\n",
        "# model.layers[0].get_weights()[1]"
      ],
      "metadata": {
        "id": "KTUlzDl0xr-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=1.0),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    history = model.fit(x_train, y_train, batch_size=256, epochs=10)\n",
        "    test_scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "metadata": {
        "id": "t3ZBxQy4xtg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AlexNet"
      ],
      "metadata": {
        "id": "gCUNGAaAxuxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 由于资源限制，所有图片都放大后，内存已经放不下了，所以需要借助Dataset进行流式处理（即实际调用，再进行resize操作）\n",
        "def resize(iter_img, batch_size = 32, img_size = None):\n",
        "    process = lambda x, y: (tf.expand_dims(x, axis=3) / 255, tf.cast(y, dtype='int32'))\n",
        "    resize_fn = lambda x, y: (tf.image.resize_with_pad(x, img_size, img_size) if img_size else x, y)\n",
        "    return tf.data.Dataset.from_tensor_slices(process(*iter_img)).batch(batch_size).shuffle(len(iter_img[0])).map(resize_fn)\n",
        "\n",
        "iter_train, iter_test = keras.datasets.fashion_mnist.load_data()\n",
        "iter_train = resize(iter_train, 128, 224)\n",
        "iter_test = resize(iter_test, 128, 224)"
      ],
      "metadata": {
        "id": "_ef3DArexyuJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(224,224,1), dtype=\"float\"),\n",
        "    tf.keras.layers.Conv2D(96, 11, activation='relu', strides=4),\n",
        "    tf.keras.layers.AvgPool2D(pool_size=3, strides=2),\n",
        "    tf.keras.layers.Conv2D(256, 5, activation='relu', padding='same'),\n",
        "    tf.keras.layers.AvgPool2D(pool_size=3, strides=2),\n",
        "    tf.keras.layers.Conv2D(384, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(384, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.Conv2D(256, 3, activation='relu', padding='same'),\n",
        "    tf.keras.layers.AvgPool2D(pool_size=3, strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(4096, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1000),\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Pawzjqm_x0Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    history = model.fit(iter_train, epochs=3)  # 此处不必再传batch_size，因为在Dataset中已经设置过了，所以此处的batch_size参数会失效\n",
        "    test_scores = model.evaluate(iter_test, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "metadata": {
        "id": "v0wgPrmex13S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet"
      ],
      "metadata": {
        "id": "lGA-gL_ix71A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 由于资源限制，所有图片都放大后，内存已经放不下了，所以需要借助Dataset进行流式处理（即实际调用，再进行resize操作）\n",
        "def resize(iter_img, batch_size = 1, img_size = None):\n",
        "    process = lambda x, y: (tf.expand_dims(x, axis=3) / 255, tf.cast(y, dtype='int32'))\n",
        "    resize_fn = lambda x, y: (tf.image.resize_with_pad(x, img_size, img_size) if img_size else x, y)\n",
        "    return tf.data.Dataset.from_tensor_slices(process(*iter_img)).batch(batch_size).shuffle(len(iter_img[0])).map(resize_fn)\n",
        "\n",
        "iter_train, iter_test = keras.datasets.fashion_mnist.load_data()\n",
        "# 这里设置image_size为32纯粹就是为了降低计算量，正常size应该是224\n",
        "iter_train = resize(iter_train, 256, 32)\n",
        "iter_test = resize(iter_test, 256, 32)"
      ],
      "metadata": {
        "id": "znyrUmYlx9Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Residual(tf.keras.Model):\n",
        "    def __init__(self, channels, strides=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(channels, kernel_size=3, padding='same', strides=strides)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(channels, kernel_size=3, padding='same')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(channels, kernel_size=1, padding='valid',strides=strides) if strides != 1 else None\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, X):\n",
        "        Y = self.conv1(X);Y = self.bn1(Y)\n",
        "        Y = tf.keras.activations.relu(Y)\n",
        "        Y = self.conv2(Y);Y = self.bn2(Y)\n",
        "        Y += X if self.conv3 is None else self.conv3(X)\n",
        "        return tf.keras.activations.relu(Y)\n",
        "\n",
        "class ResnetBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels, residuals_count, strides=2, **kwargs):\n",
        "        super(ResnetBlock, self).__init__(**kwargs)\n",
        "        self.residual_layers = []\n",
        "        self.residual_layers.append(Residual(channels, strides))\n",
        "        for i in range(residuals_count-1):\n",
        "            self.residual_layers.append(Residual(channels))\n",
        "\n",
        "    def call(self, X):\n",
        "        for layer in self.residual_layers.layers:\n",
        "            X = layer(X)\n",
        "        return X\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.Input(shape=(32,32,1), dtype=\"float\"),\n",
        "    tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same'),   # 高宽减半\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Activation('relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same'),      # 高宽减半\n",
        "    ResnetBlock(64, 2, 1),\n",
        "    ResnetBlock(128, 2),\n",
        "    ResnetBlock(256, 2),\n",
        "    ResnetBlock(512, 2),\n",
        "    tf.keras.layers.GlobalAvgPool2D(),\n",
        "    tf.keras.layers.Dense(units=10),\n",
        "])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "8f8j7FoXx-sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/device:GPU:0'):\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    history = model.fit(iter_train, epochs=5)  # 此处不必再传batch_size，因为在Dataset中已经设置过了，所以此处的batch_size参数会失效\n",
        "    test_scores = model.evaluate(iter_test, verbose=2)\n",
        "print(\"Test loss:\", test_scores[0])\n",
        "print(\"Test accuracy:\", test_scores[1])"
      ],
      "metadata": {
        "id": "aw19ABAVyATD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}